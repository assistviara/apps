import os, re, json
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
from matplotlib import font_manager, rcParams

import gspread
from google.oauth2.service_account import Credentials
from gspread_dataframe import get_as_dataframe

# ========= æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼ˆãƒ¡ã‚¤ãƒªã‚ªå„ªå…ˆã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ =========
MEIRYO_PATH = r"/usr/share/fonts/truetype/msttcorefonts/Meiryo.ttf"  # Linuxç’°å¢ƒç”¨ã®ä¾‹
try:
    if os.path.exists(MEIRYO_PATH):
        font_manager.fontManager.addfont(MEIRYO_PATH)
        rcParams["font.family"] = font_manager.FontProperties(fname=MEIRYO_PATH).get_name()
    else:
        rcParams["font.family"] = "DejaVu Sans"
except Exception:
    rcParams["font.family"] = "DejaVu Sans"
rcParams["axes.unicode_minus"] = False

# ========= è©•ä¾¡é …ç›®ï¼ˆæ­£è¦åï¼‰ =========
DIVERSITY_COLS = [
    "å¤šæ§˜æ€§1_ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®ç‹¬è‡ªæ€§","å¤šæ§˜æ€§2_å†…è£…ã®å€‹æ€§","å¤šæ§˜æ€§3_åº—ä¸»ãƒ»ã‚¹ã‚¿ãƒƒãƒ•ã®ã‚­ãƒ£ãƒ©","å¤šæ§˜æ€§4_ã‚µãƒ¼ãƒ“ã‚¹ç‹¬è‡ªæ€§",
    "å¤šæ§˜æ€§5_åœ°åŸŸæ€§ã®åæ˜ ","å¤šæ§˜æ€§6_ã‚¤ãƒ™ãƒ³ãƒˆ/å­£ç¯€","å¤šæ§˜æ€§7_SNSã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ã•","å¤šæ§˜æ€§8_å®¢å±¤ã®å¤šæ§˜æ€§",
    "å¤šæ§˜æ€§9_æä¾›æ–¹æ³•ã®ç‰¹ç•°æ€§","å¤šæ§˜æ€§10_åº—ã®ç‰©èªæ€§"
]
BRAND_COLS = [
    "é˜²è¡›1_å‘³ã®ä¿¡é ¼æ„Ÿï¼ˆåˆè¨ªï¼‰","é˜²è¡›2_è¡›ç”Ÿ/æ¸…æ½”æ„Ÿ","é˜²è¡›3_æ¥å®¢æ…‹åº¦","é˜²è¡›4_ä¾¡æ ¼ã®æ˜ç¢ºã•",
    "é˜²è¡›5_æä¾›ã‚¹ãƒ”ãƒ¼ãƒ‰","é˜²è¡›6_æ”¯æ‰•ã„ã®å®‰å…¨æ€§","é˜²è¡›7_å…¥åº—ã—ã‚„ã™ã•","é˜²è¡›8_åˆè¦‹å®¢ã¸ã®å¯¾å¿œ",
    "é˜²è¡›9_å¸¸é€£/å£ã‚³ãƒŸ","é˜²è¡›10_ãƒªã‚¹ã‚¯å¯¾å¿œåŠ›"
]
BASE_COLS = ["æ—¥ä»˜","åº—å","å‘³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆå¿…è¦æ¡ä»¶ï¼‰"]
REQUIRED_COLS = BASE_COLS + DIVERSITY_COLS + BRAND_COLS

# è¦‹å‡ºã—ã®ã‚†ã‚‰ãã‚’å¸åï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
NORMALIZE_RULES = {
    "è¨ªå•æ—¥": "æ—¥ä»˜", "ãŠåº—å": "åº—å", "Step 0": "å‘³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆå¿…è¦æ¡ä»¶ï¼‰",
    "ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®ç‹¬è‡ªæ€§": "å¤šæ§˜æ€§1_ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®ç‹¬è‡ªæ€§", "å†…è£…ã®å€‹æ€§": "å¤šæ§˜æ€§2_å†…è£…ã®å€‹æ€§",
    "åº—ä¸»": "å¤šæ§˜æ€§3_åº—ä¸»ãƒ»ã‚¹ã‚¿ãƒƒãƒ•ã®ã‚­ãƒ£ãƒ©", "ã‚µãƒ¼ãƒ“ã‚¹ç‹¬è‡ªæ€§": "å¤šæ§˜æ€§4_ã‚µãƒ¼ãƒ“ã‚¹ç‹¬è‡ªæ€§",
    "åœ°åŸŸæ€§": "å¤šæ§˜æ€§5_åœ°åŸŸæ€§ã®åæ˜ ", "ã‚¤ãƒ™ãƒ³ãƒˆ": "å¤šæ§˜æ€§6_ã‚¤ãƒ™ãƒ³ãƒˆ/å­£ç¯€", "å­£ç¯€": "å¤šæ§˜æ€§6_ã‚¤ãƒ™ãƒ³ãƒˆ/å­£ç¯€",
    "SNS": "å¤šæ§˜æ€§7_SNSã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ã•", "å®¢å±¤": "å¤šæ§˜æ€§8_å®¢å±¤ã®å¤šæ§˜æ€§",
    "æä¾›æ–¹æ³•": "å¤šæ§˜æ€§9_æä¾›æ–¹æ³•ã®ç‰¹ç•°æ€§", "ç‰©èªæ€§": "å¤šæ§˜æ€§10_åº—ã®ç‰©èªæ€§",
    "å‘³ã®ä¿¡é ¼æ„Ÿ": "é˜²è¡›1_å‘³ã®ä¿¡é ¼æ„Ÿï¼ˆåˆè¨ªï¼‰", "è¡›ç”Ÿ": "é˜²è¡›2_è¡›ç”Ÿ/æ¸…æ½”æ„Ÿ", "æ¸…æ½”": "é˜²è¡›2_è¡›ç”Ÿ/æ¸…æ½”æ„Ÿ",
    "æ¥å®¢": "é˜²è¡›3_æ¥å®¢æ…‹åº¦", "ä¾¡æ ¼ã®æ˜ç¢ºã•": "é˜²è¡›4_ä¾¡æ ¼ã®æ˜ç¢ºã•", "æä¾›ã‚¹ãƒ”ãƒ¼ãƒ‰": "é˜²è¡›5_æä¾›ã‚¹ãƒ”ãƒ¼ãƒ‰",
    "æ”¯æ‰•ã„": "é˜²è¡›6_æ”¯æ‰•ã„ã®å®‰å…¨æ€§", "å…¥åº—ã—ã‚„ã™ã•": "é˜²è¡›7_å…¥åº—ã—ã‚„ã™ã•",
    "åˆè¦‹å®¢": "é˜²è¡›8_åˆè¦‹å®¢ã¸ã®å¯¾å¿œ", "å£ã‚³ãƒŸ": "é˜²è¡›9_å¸¸é€£/å£ã‚³ãƒŸ", "ãƒªã‚¹ã‚¯å¯¾å¿œåŠ›": "é˜²è¡›10_ãƒªã‚¹ã‚¯å¯¾å¿œåŠ›",
}

MIDLINE = 30
MIN_SCORE, MAX_SCORE = 1, 5

def extract_sheet_id(text: str) -> str:
    m = re.search(r"/d/([a-zA-Z0-9-_]+)/", text.strip())
    return m.group(1) if m else text.strip()

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    new_cols = []
    for c in df.columns:
        cc, mapped = str(c), None
        for key, dest in NORMALIZE_RULES.items():
            if key in cc:
                mapped = dest; break
        new_cols.append(mapped or cc)
    df.columns = new_cols
    return df

@st.cache_data(show_spinner=False)
def load_sheet(creds_dict: dict, sheet_id: str, worksheet: str) -> pd.DataFrame:
    creds = Credentials.from_service_account_info(creds_dict, scopes=["https://www.googleapis.com/auth/spreadsheets.readonly"])
    gc = gspread.authorize(creds)
    sh = gc.open_by_key(sheet_id)
    ws = sh.worksheet(worksheet)
    df = get_as_dataframe(ws, evaluate_formulas=True, header=0)
    df = df.dropna(how="all")
    return normalize_columns(df)

def coerce_scores(df: pd.DataFrame) -> pd.DataFrame:
    for c in DIVERSITY_COLS + BRAND_COLS:
        s = pd.to_numeric(df[c], errors="coerce").clip(MIN_SCORE, MAX_SCORE).fillna(MIN_SCORE).astype(int)
        df[c] = s
    return df

def deduplicate(df: pd.DataFrame, keys=("åº—å","æ—¥ä»˜"), ts_col="ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—"):
    if all(k in df.columns for k in keys):
        if ts_col in df.columns:
            d = df.copy()
            d["_ts"] = pd.to_datetime(d[ts_col], errors="coerce")
            d = d.sort_values("_ts").drop_duplicates(subset=list(keys), keep="last").drop(columns=["_ts"])
            return d
        return df.drop_duplicates(subset=list(keys), keep="last")
    return df

def compute_totals(df: pd.DataFrame) -> pd.DataFrame:
    df["å¤šæ§˜æ€§åˆè¨ˆ"] = df[DIVERSITY_COLS].sum(axis=1)
    df["é˜²è¡›åˆè¨ˆ"] = df[BRAND_COLS].sum(axis=1)
    mask = df["å‘³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆå¿…è¦æ¡ä»¶ï¼‰"].astype(str).str.strip().str.lower().eq("yes")
    df["_plot_x"] = df["å¤šæ§˜æ€§åˆè¨ˆ"].where(mask)
    df["_plot_y"] = df["é˜²è¡›åˆè¨ˆ"].where(mask)
    return df

def draw_plot(df: pd.DataFrame):
    fig, ax = plt.subplots(figsize=(8.8, 5.6), dpi=120)
    plot_df = df.dropna(subset=["_plot_x","_plot_y"])
    ax.scatter(plot_df["_plot_x"], plot_df["_plot_y"], s=42)
    ax.axvline(MIDLINE, color="grey", lw=1); ax.axhline(MIDLINE, color="grey", lw=1)
    ax.set_xlim(0,50); ax.set_ylim(0,50)
    ax.set_xlabel("å¤šæ§˜æ€§åˆè¨ˆï¼ˆ1ã€œ5Ã—10ï¼10ã€œ50ï¼‰")
    ax.set_ylabel("ãƒ–ãƒ©ãƒ³ãƒ‰é˜²è¡›åˆè¨ˆï¼ˆ1ã€œ5Ã—10ï¼10ã€œ50ï¼‰")
    ax.set_title("é£²é£Ÿåº—ã‚¹ã‚³ã‚¢ãƒ»ãƒãƒˆãƒªã‚¯ã‚¹ï¼ˆå‘³OKã®ã¿ãƒ—ãƒ­ãƒƒãƒˆï¼‰")
    st.pyplot(fig, clear_figure=True)

# ===================== UI =====================
st.set_page_config(page_title="é£²é£Ÿåº—ã‚¹ã‚³ã‚¢ãƒ»ãƒãƒˆãƒªã‚¯ã‚¹", layout="wide")
st.title("é£²é£Ÿåº—ã‚¹ã‚³ã‚¢ãƒ»ãƒãƒˆãƒªã‚¯ã‚¹ï¼ˆGoogleãƒ•ã‚©ãƒ¼ãƒ  â†’ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆï¼‰")

# Secretsï¼ˆStreamlit Cloud ã®ã€ŒSettings > Secretsã€ã¸è¨­å®šï¼‰
# ä¾‹:
# [gcp]
# service_account_json = {...}  # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®JSONä¸€å¼
# sheet_id = "xxxxxxxxxxxxxxxxxxxx"
# worksheet = "Form Responses"
svc_json = st.secrets["gcp"]["service_account_json"]
default_sheet_id = st.secrets["gcp"].get("sheet_id", "")
default_ws = st.secrets["gcp"].get("worksheet", "Form Responses")

col1, col2 = st.columns(2)
with col1:
    sheet_id_input = st.text_input("Spreadsheet ID / URL", value=default_sheet_id, placeholder="IDã¾ãŸã¯URLã‚’å…¥åŠ›")
with col2:
    ws_name = st.text_input("Worksheetåï¼ˆã‚¿ãƒ–åï¼‰", value=default_ws, placeholder="ä¾‹ï¼šForm Responses / ãƒ•ã‚©ãƒ¼ãƒ ã®å›ç­” 1")

if st.button("èª­ã¿è¾¼ã¿ï¼†ãƒ—ãƒ­ãƒƒãƒˆ", type="primary"):
    try:
        sid = extract_sheet_id(sheet_id_input)
        df = load_sheet(json.loads(svc_json), sid, ws_name)
        # å¿…è¦åˆ—ãƒã‚§ãƒƒã‚¯
        missing = [c for c in REQUIRED_COLS if c not in df.columns]
        if missing:
            st.error(f"å¿…è¦åˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing}")
        else:
            df = coerce_scores(df)
            before = len(df)
            df = deduplicate(df, keys=("åº—å","æ—¥ä»˜"), ts_col="ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—")
            after = len(df)
            st.caption(f"é‡è¤‡é™¤å»: {before - after}ä»¶ï¼ˆã‚­ãƒ¼: åº—åÃ—æ—¥ä»˜ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æœ€æ–°ã‚’æ¡ç”¨ï¼‰")
            df = compute_totals(df)

            draw_plot(df)
            st.dataframe(df[BASE_COLS + ["å¤šæ§˜æ€§åˆè¨ˆ","é˜²è¡›åˆè¨ˆ"]].sort_values(["æ—¥ä»˜","åº—å"]))

            csv = df.to_csv(index=False).encode("utf-8-sig")
            st.download_button("CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="scores_cleaned.csv", mime="text/csv")
    except Exception as e:
        st.exception(e)

st.markdown("---")
st.write("ğŸ’¡ ãƒ¡ãƒ¢ï¼šã“ã®ã‚¢ãƒ—ãƒªã¯ *Yes* ã®å‘³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ã¿ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã€å¢ƒç•Œã¯ 30 ç‚¹ï¼ˆ10é …ç›®Ã—3ï¼‰ã§ã™ã€‚è¦‹å‡ºã—ãŒå¾®å¦™ã«é•ã£ã¦ã‚‚è‡ªå‹•ã§å¯„ã›ã¾ã™ã€‚")
